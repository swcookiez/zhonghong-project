hive优化
1.join
小表join大表 map join
将数据倾斜的key打散，小表对应的key进行扩容进行join，后union
大表join大表 空值过滤 空值随机值 SMB join

2. group
开启combinner预聚合
开启两阶段聚合，可以自己实现
使用group by 代替 distinct

3. 行列过滤
4. 开启分区
5. 列式存储
6. 开启压缩
7. 合理设置map、reduce个数
map
小文件过多情况下：可以设置combineinputFormater为读取格式，逻辑上会将多个小文件当做一个文件处理
文件较大且逻辑复杂情况下，可改变切片大小。产生多个map任务
reduce
输出数据量较小时，应该减少reduce的个数，避免生成大量小文件
reduce端处理数据量大时，可以自定义分区，使数据均匀发散到各reduce中去
小文件merge，har归档，自定义mr程序合并小文件

8. 开启jvm重用，每个map任务都会开启一个jvm，重用后节约了jvm启动时间。

9. 并行执行

10. 使用spark执行引擎

数据倾斜
1)group by 代替 distinct
2)mapjoin
3)数据倾斜负载均衡
4)两阶段聚合,对数据进行抽样,过滤出key较大的数据进行两阶段聚合
select count(1),city from(select * from(select *,random() r from A)t1  where r > 0.1 and r <0.2)t2
group by city
加上随机前缀，先做一段聚合后，去掉前缀再做二段聚合
5)增大reduce内存
6)空值过滤


